\chapter{Related Work}
\label{chap:rel_wk}

In the following chapter are reported some research work related on topics
covered in this thesis. 

\section{Related work on NFV}
In the market it is possible to find different research and implementations in
different scenarios.

An example is the one described in~\cite{nogales2018nfv}in
which the ETSI MANO architecture is proposed on the top a network of drones.
This open a wide range of possibilities, allowing to provide connectivity even
in areas where there are not an infrastructure or it is momentarily not
available, for example after a natural disaster. Even if this solution is really
flexible and quick to deploy need a VIM infrastructure to which to be connected.

In~\cite{yu2015network}, authors are instead oriented on the study of the
opportunity to deploy the overall system on the top of multi-tenant cloud
architectures. Challenges in this context concern mainly the possibility to
enforce requirements, such as policies and performance. Moreover, demanding to
the cloud infrastructure the resource management means that it must be able to
optimize the resource utilization.

A significant proposal was presented in~\cite{cziva2017container}, that is one
of the first paper that evaluate the possibility to use container technology on
the network edges. This work is based on~\cite{cziva2015container} in which the
authors define an architecture to orchestrate containers, whose components can
be mapped on ETSI MANO architectural definition. The usage of containers enable
the possibility of deployment on less powerful devices and putting them on
network edge open a wide range of opportunities to classify packets and treat
them in an adequate manner as soon as possible. Another paper that propose the
use of containers for VNF is~\cite{hoang2018extended}, in which function are
deployed both on Openstack and in Kubernetes as VIMs, using TOSCA definition to
describe containers and Tacker for the management as network function
orchestrator, even if they does not provide an evaluation of the solution.
Another aspect to consider is that they not mention the possibility to composed
their function. Finally, as author stated, standard does not support fully
features for container by now.


\section{Related work on network slicing}
Network slicing is one of the most important technology improvements that allows
to move towards the 5G technology. In~\cite{chartsias2017sdn} is presented a
network slicing approach based on SDN in multi-tenancy scenarios. The testbed
implemented propose a centralized approach to manage physical and virtual
resources in different slices. In~\cite{peuster2016medicine} instead, authors
describe a NFV-based platform, that allows management and orchestration showing
the importance of virtual function in the network slicing context.

This emerging technology open a wide number of new challenges. An example is the
possibility to ensure proper security on communication, that is harder even due
to the concept of shared services, that could not provide suitable isolation. 
In~\cite{kotulski2017end} authors describes possible security issues, stating
that the isolation required may vary depending on usage scenarios. Even the ETSI
MANO system consider isolation only in terms of performance level. Other
challenges are highlighted in~\cite{li2017network}, in which in addition to
isolation and security concerns, point out that resource allocation and
sharing algorithms possible problems and that some virtualization method, used
in wired context, cannot be applied in wireless counterpart.

\section{Related work on VNF management and orchestration}
The MANO component in ETSI architecture, goal is to manage lifecycle of network
function to offer end-to-end services. As underlined in~\cite{kotulski2017end}
this reference model is very general and leave to implementation the task to
solve some problems. This architectural component also is accountable of the SFC
path flexibility. Some implementations, like~\cite{soares2015toward}
and~\cite{abujoda2015midas} does not allow path updating, removing the
possibility to change chain composition during its lifetime.

\section{Related work on SFCs}

Since the SFC technology was proposed many work came out proposing different
implementation solutions. In this part there is an overview of some of them.

\cite{GhaznaviSAB16} proposed an optimization model to calculate the optimal
location of VNFs based on different metrics such as bandwidth, load balancing
and routes. This decomposes the SFC on performance requirements eliminating the
throughput bound of a chain to a single VNF or a single physical machine.
Mathematical models developed was tested in a simulation environment. A critical
enhancement to this work could be to test algorithm in a real environment, under
different conditions of traffic load: if it efficient even in this scenario it
can be useful to the orchestration and management part of the ecosystem because
it can reduce resource waste.

Other implementation tested in a simulated environment
are~\cite{csoma2014escape} and~\cite{kim2016evaluations}. In both of them the
network functions are deployed on Mininet. The former work provides a full
implementation of the SFC environment, including SFC configuration, allocating
VNFs into the physical resources, flow routing across the VNFs based on
policies, and provisioning live management information on operating VNF
instances, but no performance evaluation of the work is presented. In the latter
case chains are identified by VLAN tag and the VNF chaining is created
exploiting only using Floodlight controllers.

Another noteworthy work is~\cite{xia2015optical} that discuss the packet
delivery through function chaining in high capacity networks exploiting
aggregate flow steering. The architecture proposed makes use of SDN and cloud
platforms to deploy VMs that will host VNFs. Assumption are made about the SDN
network elements: connection through optical circuit switching and use of Wave
Selective Switching (WSS) to route (switch) signals between optical fibers on a
per-wavelength basis. Thanks to the implementation of the SDN controller and the
communication between the previous element and the VNFM, this architecture is
able to provide good capabilities in terms of flexibility. Another element that
helps the flexibility is the high performance link: in this way they get rid of
problems in terms of connection time and bandwidth. However, in the paper
authors assumes really specific hardware in the underlying infrastructure that
connects the overall system: this is not suitable to be deployed in a general
purpose infrastructure or using IaaS. It will be interesting to evaluate the
same work on different instrumentation. A clashing aspect is the time to make a
VM up and running compared to times of service chaining configuration/packet
delivery. Using containers the instantiation of virtual functions should employ
less time.

A relevant work on function chaining in network is~\cite{trajkovska2017sdn}. In
this work author efforts are concentrated on joining SDN and VNF technologies to
create SFCs. They developed an SDN-driven SDK, a virtual traffic classifier to
analyze traffic in real-time and decide the optimal chain for it and a VNF
specialized on video transdecoding, used event to evaluate the performances of
the whole system. Chaining is performed exploiting layer 2 connectivity, using
OpenvSwitch as virtual network switches an OpenDayLight in order to route the
traffic on a set of policies. However the solution does not provide any
mechanism to perform an automatic deployment of chains and services: this can be
an issue in particular in case of VNF fault. Orchestration and some mechanisms
of fault tolerance are critical in particular in a real environment, enabling
autoscaling on user demand or traffic load. Automated deployment also make
possible the recreation of a virtual machine in case of fault. As a matter of
fact that a virtual function can fail depending on an erroneous load balancing
policy or too heavy computational load and it is critical in order to do not
interrupt end-to-end communication to bring up the VNF as soon as possible. This
recreation process can be slow due to the usage of VMs to deploy the functions,
that could take minutes to startup.

The paper~\cite{kriti2017dnfc} introduce the possibility using container in SFC
deployment. The chain of container is created exploiting Openflow to create flow
to route traffic to the containers, that have to be installed on the host
machine. This work however does present any form of management or orchestration
of the chain, neither an automatic deployment. Moreover it requires installation
of part of the system on the host machine: in this way there is not a fully
virtualized environment. The former issue has some implication: the VNF has a
strong relation on the host on which is running and the system could not be
simply be moved from one machine to another as it could be done only using
containers. Finally this paper does not provide any form of system evaluation
neither in terms of performances nor in terms of resilience. Fault recovering
and autoscaling could be achieved only improving the system introducing other
technologies, such as Docker Compose, Kubernetes or Docker Swarm.






